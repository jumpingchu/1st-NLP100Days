{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作業目的:了解決策樹的節點分支依據\n",
    "本次作業可參考簡報中的延伸閱讀[訊息增益](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda)部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question:\n",
    "若你是決策樹，下列兩種分類狀況(a,b)，你會選擇哪種做分類？為什麼？\n",
    "\n",
    "<img src='hw_1.png' style='width:500px'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8112781244591328, 0.8112781244591328)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_L = entropy((15, 5), base=2)\n",
    "a_R = entropy((5, 15), base=2)\n",
    "a_L, a_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9852281360342515, 0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_L = entropy((15, 20), base=2)\n",
    "b_R = entropy((5, 0), base=2)\n",
    "b_L, b_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1 - (20/40 * a_L) - (20/40 * a_R)\n",
    "b = 1 - (35/40 * b_L) - (5/40 * b_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy a: 0.19\n",
      "entropy b: 0.14\n"
     ]
    }
   ],
   "source": [
    "print('entropy a:', round(a, 2))\n",
    "print('entropy b:', round(b, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 基於最大資訊增益: entropy a > b\n",
    "* 會選擇 a 方法做分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 閱讀作業\n",
    "\n",
    "決策樹根據計算分割準則的不同(ex: Entropy, Gini, Gain ratio)，可分為ID3, C4.5, CART樹的算法，請同學閱讀下列文章，來更加了解決策樹的算法。\n",
    "\n",
    "[決策樹(ID3, C4.5, CART)](https://blog.csdn.net/u010089444/article/details/53241218)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID3 算法\n",
    "* 首先計算出原始數據集的熵，然後依次將數據中的每一個特徵作為分支標準\n",
    "* 計算其相對於原始數據的資訊增益，選擇最大資訊增益的分支標準來劃分數據\n",
    "* 資訊增益越大，區分樣本的能力就越強，越具有代表性 = 分支的樣本數越少越好"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C4.5 算法\n",
    "* 是對 ID3 算法的改進，克服了 ID3 的 2 個缺點：\n",
    "    * 用資訊增益選擇屬性時偏向於選擇分枝比較多的屬性值，即取值多的屬性\n",
    "    * 不能處理連續屬性\n",
    "* 對於離散特徵，不直接使用信息增益，而是使用“增益率”（gain ratio）來選擇最優的分支標準\n",
    "* 增益率準則對可取值數目較少的屬性有所偏好，因此並不是直接選擇增益率最大的屬性作為分支標準，而是先從候選屬性中找出資訊增益高於平均水平的屬性，再從中選擇增益率最高的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CART（Classification And Regression Tree）算法\n",
    "* 分支標準建立在 GINI 指數這個概念上\n",
    "\n",
    "\n",
    "* 存在數據過度擬合問題\n",
    "    * 由於訓練數據中的噪音或孤立點，許多分枝反映的是訓練數據中的異常，使用這樣的判定樹對類別未知的數據進行分類，分類的準確性不高\n",
    "    * 因此試圖檢測和減去這樣的分支，檢測和減去這些分支的過程被稱為樹剪枝\n",
    "    \n",
    "    \n",
    "* 樹剪枝方法用於處理過分適應數據問題，減去最不可靠的分支 => 較快的分類，提高樹獨立於訓練數據正確分類的能力。\n",
    "\n",
    "\n",
    "#### 預剪枝 (Pre-Pruning) 是根據一些原則及早的停止樹增長，例如：\n",
    "* 樹的深度達到用戶所要的深度\n",
    "* 節點中樣本個數少於用戶指定個數\n",
    "* 不純度指標下降的最大幅度小於用戶指定的幅度\n",
    "    \n",
    "#### 後剪枝 (Post-Pruning) 是通過在完全生長的樹上剪去分枝實現的\n",
    "* 通過刪除節點的分支來剪去樹節點\n",
    "* 可以使用的後剪枝方法有多種，例如：\n",
    "    * 代價複雜性剪枝\n",
    "    * 最小誤差剪枝\n",
    "    * 悲觀誤差剪枝"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
