{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 瞭解如何實作與使用Tree Base 模型\n",
    "在先前的課程中，學習到了經典的樹型模型(Decision Tree, Random Forest, Adaboost)，在這次的課程中，將會透過實作來更加了解樹型模型的運作。本次的課程將會著重在決策樹(Decision Tree)與隨機森林(Random Forest)的實作與使用上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入需要的套件(Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成假數據\n",
    "在這次的課程中，我們會著重在演算法的實作。在資料部分，我們使用自行生成的數據來進行練習。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "      <th>diameter</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Green</td>\n",
       "      <td>3.1</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>3.2</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Grape</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yellow</td>\n",
       "      <td>3.3</td>\n",
       "      <td>Lemon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color  diameter  label\n",
       "0   Green       3.1  Apple\n",
       "1  Yellow       3.2  Apple\n",
       "2     Red       1.2  Grape\n",
       "3     Red       1.0  Grape\n",
       "4  Yellow       3.3  Lemon"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = [\n",
    "    ['Green', 3.1, 'Apple'],\n",
    "    ['Yellow', 3.2, 'Apple'],\n",
    "    ['Red', 1.2, 'Grape'],\n",
    "    ['Red', 1, 'Grape'],\n",
    "    ['Yellow', 3.3, 'Lemon'],\n",
    "    ['Yellow', 3.1, 'Lemon'],\n",
    "    ['Green', 3, 'Apple'],\n",
    "    ['Red', 1.1, 'Grape'],\n",
    "    ['Yellow', 3, 'Lemon'],\n",
    "    ['Red', 1.2, 'Grape'],\n",
    "]\n",
    "\n",
    "header = [\"color\", \"diameter\", \"label\"]\n",
    "\n",
    "df = pd.DataFrame(data=training_data, columns=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 輔助函式(Utility Functions)\n",
    "在這部分我們會定義多個輔助我們實作過程中會需要的輔助函式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割測試集與訓練集  \n",
    "def train_test_split(df, test_size=0.1):\n",
    "    \n",
    "    if isinstance(test_size, float):\n",
    "        test_size = round(test_size * len(df))\n",
    "\n",
    "    #以隨機的方式取得測試集資料點的 index\n",
    "    indices = list(df.index)\n",
    "    test_indices = random.sample(population=indices, k=test_size)\n",
    "\n",
    "    #分割測試集與訓練集\n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return train_df, test_df\n",
    "\n",
    "\n",
    "# 檢查資料是否都為同一類別（leaf node）\n",
    "def check_purity(data):\n",
    "    '''Function to check if input data all belong to the same class\n",
    "    Parameter\n",
    "    ---------\n",
    "    data: list\n",
    "        Input data\n",
    "    '''\n",
    "    #取得資料的 label 訊息\n",
    "    labels = data[:, -1]\n",
    "    \n",
    "    #檢查是否所有的label都為同一種\n",
    "    unique_classes = np.unique(labels)\n",
    "    \n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 與模型相關的函式\n",
    "在實現模型時，會需要很多的處理，此處將與實現模型相關的處理建構成函式，以便重複利用與增加程式的可讀性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根據給定的資料，取得每個特徵(feature)可能做為樹型模型分割節點的值\n",
    "# 可能作為分割節點得值即為每個特徵的獨特值(unique value)\n",
    "def get_potential_splits(data):\n",
    "    '''Function to get all potential split value for tree base model\n",
    "    Parameter\n",
    "    ----------\n",
    "    data: list\n",
    "        Input data\n",
    "    '''\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    \n",
    "    #此處的-1是為了扣掉label的欄位\n",
    "    for column_index in range(n_columns - 1):    \n",
    "        \n",
    "        #根據欄位取的特徵的獨特值(unique values)\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        #將取得的可能分割值除存在potential_split的字典中(key=特徵欄位的index, value:此特徵可能的分割值)\n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits\n",
    "\n",
    "\n",
    "#由給定的輸入DataFrame給個特徵值的型態(數值型特徵或類別型特徵)\n",
    "def determine_type_of_feature(df):\n",
    "    '''Function to get features types\n",
    "    Parameter\n",
    "    ---------\n",
    "    df: pd.DataFrame\n",
    "        Input raw pd.DataFrame data\n",
    "    '''\n",
    "    \n",
    "    feature_types = []\n",
    "    \n",
    "    #若特徵的獨特值個數較少，即當作類別型特徵資料(若為數值型，獨特值個數應該會很多)\n",
    "    #此處簡易的將判斷方法設為資料個數的1/3次方，此值可以自行修改選較為適合的個數\n",
    "    n_unique_values_treshold = int(len(df)**(1/3))\n",
    "    \n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            rep_value = unique_values[0] #選出一個值做此特徵的代表\n",
    "\n",
    "            if (isinstance(rep_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types\n",
    "\n",
    "\n",
    "# 根據給定的資料、欲採用特徵欄位指標(index)與欲採用的分割值，來取的分割節點分割後的左節點資料與右節點資料\n",
    "def split_data(data, split_column, split_value):\n",
    "    '''Function to splitted left and right nodes\n",
    "    Parameter\n",
    "    ---------\n",
    "    data: list\n",
    "        Input data\n",
    "    split_column: int\n",
    "        index for feature column\n",
    "    split_value: float or int or string\n",
    "        value to be used as split benchmark\n",
    "    '''\n",
    "    \n",
    "    #取得用來分割的特徵欄位\n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    #依據欄位值的型態(數值型特徵或類別型特徵)來進行節點分割\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    \n",
    "    if type_of_feature == \"continuous\":\n",
    "        #數值型特徵分割\n",
    "        data_left = data[split_column_values <= split_value]\n",
    "        data_right = data[split_column_values >  split_value]\n",
    "    else:\n",
    "        #類別型特徵分割\n",
    "        data_left = data[split_column_values == split_value]\n",
    "        data_right = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_left, data_right\n",
    "\n",
    "\n",
    "# 根據給定的資料與任務類型(回歸或分類)來產生終端節點\n",
    "def create_leaf(data, task_type):\n",
    "    '''Function to create leaf node\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: list\n",
    "        Input data\n",
    "    task_type: str\n",
    "        indicate the type of tree (regression or classification)\n",
    "    '''\n",
    "    \n",
    "    #取的資料的label欄位\n",
    "    label_column = data[:, -1]\n",
    "    \n",
    "    if task_type == \"regression\":\n",
    "        #回歸任務\n",
    "        leaf = np.mean(label_column)\n",
    "    else:\n",
    "        #分類任務\n",
    "        #取得所有輸入資料的獨立類別與其個數\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "        \n",
    "        #以個數最多的類別，作為此節點的輸出類別\n",
    "        index = counts_unique_classes.argmax()\n",
    "        leaf = unique_classes[index]\n",
    "    \n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['categorical', 'continuous']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "determine_type_of_feature(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定義熵(Entropy)來計算訊息增益\n",
    "在計算節點是否分割時，會計算訊息增益，已取得最高的訊息增益為目標進行節點分割(讀者可參考決策樹部分課程內容)，此處採用熵(Entropy)來計算\n",
    "訊息增益\n",
    "\n",
    "$$\n",
    "Entropy = -\\sum_{i=1}^cp(i)log_2p(i)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算資料的熵(Entropy)\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    #取的資料的label訊息\n",
    "    label_column = data[:, -1]\n",
    "    \n",
    "    #取得所有輸入資料的獨立類別與其個數\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    #計算機率\n",
    "    probabilities = counts / counts.sum()\n",
    "    \n",
    "    #計算entropy\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy\n",
    "\n",
    "\n",
    "#取得左節點與右節點訊息合\n",
    "def calculate_overall_metric(data_below, data_above, metric_function):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_metric =  (p_data_below * metric_function(data_below) \n",
    "                     + p_data_above * metric_function(data_above))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "#以迴圈的方式計算所有可能分割值的訊息增益，取的最佳的分割特徵與值(訊息增益最大)\n",
    "def determine_best_split(data, potential_splits, metric_function, task_type='classification'):\n",
    "    \n",
    "    #紀錄是否為樹的第一層(第一次回圈)\n",
    "    first_iteration = True\n",
    "    \n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            \n",
    "            #根據給定的特徵與分割值分割資料為左節點、右節點\n",
    "            data_left, data_right = split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "            #判斷是回歸樹亦或分類樹\n",
    "            if task_type == \"regression\":\n",
    "                #回歸樹\n",
    "                current_overall_metric = calculate_overall_metric(data_left, data_right, metric_function=metric_function)\n",
    "            else:\n",
    "                #分類樹\n",
    "                current_overall_metric = calculate_overall_metric(data_left, data_right, metric_function=metric_function)\n",
    "\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                \n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 決策樹(Decision Tree)模型\n",
    "此處利用上述定義的輔助韓式來搭建決策樹模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree():\n",
    "    '''Decision Tree model\n",
    "    Parameters\n",
    "    -----------\n",
    "    metric_function: function\n",
    "        the metric function used to calculate information gain\n",
    "    task_type: str\n",
    "        indicate the type of tree (regression or classification)\n",
    "    counter: int\n",
    "        counter for recording number of splits\n",
    "    min_samples: int\n",
    "        minimum number of samples for a node to be able to split\n",
    "    max_depth: int\n",
    "        Maximum depth for the decision tree\n",
    "    '''\n",
    "    def __init__(self, metric_function, task_type='classification', counter=0, min_samples=2, max_depth=5):\n",
    "        \n",
    "        self.metric_function = metric_function\n",
    "        self.task_type = task_type\n",
    "        self.counter = counter\n",
    "        self.min_samples = min_samples\n",
    "        self.max_depth = max_depth\n",
    "    \n",
    "    def fit(self, df):\n",
    "        '''\n",
    "        df: pd.DataFrame\n",
    "            input raw DataFrame data\n",
    "        '''\n",
    "        # 資料準備\n",
    "        if self.counter == 0:\n",
    "            #若為第一次分割，取出資料特徵的欄位與其對應的型態\n",
    "            global COLUMN_HEADERS, FEATURE_TYPES\n",
    "\n",
    "            #取得資料特徵欄位\n",
    "            COLUMN_HEADERS = df.columns\n",
    "            #取的特徵型態\n",
    "            FEATURE_TYPES = determine_type_of_feature(df)\n",
    "            #取得資料特徵值\n",
    "            data = df.values\n",
    "        else:\n",
    "            #取得資料特徵值\n",
    "            data = df           \n",
    "\n",
    "        # 終端節點處理(leaf)\n",
    "        # 若資料都屬於同一種類別、資料個數小於最小可分割個數、樹的深度大於最大深度，節點即屬於終端節點(leaf)\n",
    "        if (check_purity(data)) or (len(data) < self.min_samples) or (self.counter == self.max_depth):\n",
    "            leaf = create_leaf(data, self.task_type)\n",
    "            return leaf\n",
    "\n",
    "        # 分割節點\n",
    "        else:    \n",
    "            self.counter += 1\n",
    "\n",
    "            # 節點分割的左節點與右節點\n",
    "            potential_splits = get_potential_splits(data)\n",
    "            split_column, split_value = determine_best_split(data, potential_splits,\n",
    "                                                             self.metric_function, self.task_type)\n",
    "            data_left, data_right = split_data(data, split_column, split_value)\n",
    "\n",
    "            # 若分割後的左節點或右節點sample個數為零(代表母節點即無法再分割)\n",
    "            if len(data_left) == 0 or len(data_right) == 0:\n",
    "                # 取出此節點\n",
    "                leaf = create_leaf(data, self.task_type)\n",
    "                return leaf\n",
    "\n",
    "            # 取得分割節點的分割依據(特徵與分切值)\n",
    "            feature_name = COLUMN_HEADERS[split_column]\n",
    "            type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "            if type_of_feature == \"continuous\":\n",
    "                #連續型數值\n",
    "                question = \"{} <= {}\".format(feature_name, split_value)\n",
    "            else:\n",
    "                #類別型數值\n",
    "                question = \"{} = {}\".format(feature_name, split_value)\n",
    "\n",
    "            # 建構子樹(sub-tree)\n",
    "            sub_tree = {question: []}\n",
    "\n",
    "            # 已遞迴的方式取建構完整決策樹    \n",
    "            yes_answer = self.fit(data_left)\n",
    "            no_answer = self.fit(data_right)\n",
    "            #yes_answer = decision_tree(data_left, metric_function, task_type, counter, min_samples, max_depth)\n",
    "            #no_answer = decision_tree(data_right, metric_function, task_type, counter, min_samples, max_depth)\n",
    "\n",
    "            #若左節點與右節點分割的結果相同，則此節點即不需再進行分割\n",
    "            #此情形會發生在「此節點資料個數小於 min_samples」或「樹深度大於 max_depth」\n",
    "            if yes_answer == no_answer:\n",
    "                sub_tree = yes_answer\n",
    "            else:\n",
    "                sub_tree[question].append(yes_answer)\n",
    "                sub_tree[question].append(no_answer)\n",
    "            \n",
    "            self.sub_tree = sub_tree\n",
    "            \n",
    "            return sub_tree\n",
    "        \n",
    "    def pred(self, example, tree):\n",
    "        # 使用訓練好的決策樹進行預測\n",
    "        \n",
    "        #取得分割節點(由上到下)\n",
    "        question = list(tree.keys())[0]\n",
    "        feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "        #以節點分割問題分類資料\n",
    "        if comparison_operator == \"<=\":\n",
    "            #數值型資料\n",
    "            if example[feature_name] <= float(value):\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "        else:\n",
    "            #類別型資料\n",
    "            if str(example[feature_name]) == value:\n",
    "                answer = tree[question][0]\n",
    "            else:\n",
    "                answer = tree[question][1]\n",
    "        \n",
    "        # 若分類完成，返回分類結果\n",
    "        if not isinstance(answer, dict):\n",
    "            return answer\n",
    "        else:\n",
    "            #繼續往下分類\n",
    "            residual_tree = answer\n",
    "            return self.pred(example, residual_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用決策樹進行訓練與預測\n",
    "這部分我們會將生成的假數據切分成訓練集與測試集，並以實作的決策樹來對資料進行訓練與預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'diameter <= 1.2': ['Grape',\n",
       "  {'color = Yellow': [{'diameter <= 3.2': [{'diameter <= 3.1': ['Lemon',\n",
       "        'Apple']},\n",
       "      'Lemon']},\n",
       "    'Apple']}]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#分割資料集\n",
    "train_df, test_df = train_test_split(df, 0.2)\n",
    "\n",
    "#以訓練集訓練決策樹\n",
    "tree = decision_tree(calculate_entropy, 'classification', 0, min_samples=2, max_depth=5)\n",
    "tree.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color       Yellow\n",
       "diameter         3\n",
       "label        Lemon\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lemon'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 以建構好的樹進行預測\n",
    "sample = test_df.iloc[0]\n",
    "tree.pred(sample, tree.sub_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "color       Yellow\n",
       "diameter         3\n",
       "label        Lemon\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
