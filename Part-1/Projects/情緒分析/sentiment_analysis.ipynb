{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = BeautifulSoup(open('electronics/positive.review', encoding='utf8')).find_all('review_text')\n",
    "positive_text = [review.text.strip() for review in positive]\n",
    "\n",
    "negative = BeautifulSoup(open('electronics/negative.review', encoding='utf8')).find_all('review_text')\n",
    "negative_text = [review.text.strip() for review in negative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = [word.rstrip() for word in open('stopwords.txt')]\n",
    "stopwords[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['back-ups',\n",
       " 'recommendation',\n",
       " 'employee',\n",
       " 'mine',\n",
       " 'month',\n",
       " 'functioned',\n",
       " 'properly',\n",
       " 'unexpected',\n",
       " 'power',\n",
       " 'interruption',\n",
       " 'gladly',\n",
       " 'arises',\n",
       " 'plug',\n",
       " 'spacing',\n",
       " 'power',\n",
       " 'adapter',\n",
       " 'simple',\n",
       " 'design',\n",
       " 'cord',\n",
       " 'line',\n",
       " 'conditioning',\n",
       " 'usually',\n",
       " 'expensive',\n",
       " 'option']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(positive_text[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenizer(review):\n",
    "    tokens = nltk.tokenize.word_tokenize(review.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens] # 過濾文法變化\n",
    "    tokens = [token for token in tokens if len(token) > 3 and token not in stopwords] # 過濾掉過短單字 & stopwords\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(word_idx_map): 10147\n"
     ]
    }
   ],
   "source": [
    "word_idx_map = {}\n",
    "current_idx = 0\n",
    "pos_tokenized = []\n",
    "neg_tokenized = []\n",
    "origin_reviews = []\n",
    "\n",
    "for review in positive_text:\n",
    "    origin_reviews.append(review)\n",
    "    tokens = tokenizer(review)\n",
    "    pos_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_idx_map:\n",
    "            word_idx_map[token] = current_idx\n",
    "            current_idx += 1\n",
    "\n",
    "for review in negative_text:\n",
    "    origin_reviews.append(review)\n",
    "    tokens = tokenizer(review)\n",
    "    pos_tokenized.append(tokens)\n",
    "    for token in tokens:\n",
    "        if token not in word_idx_map:\n",
    "            word_idx_map[token] = current_idx\n",
    "            current_idx += 1\n",
    "\n",
    "print(\"len(word_idx_map):\", len(word_idx_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 33)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx_map['amazon'], word_idx_map['recommendation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_vector(tokens, label):\n",
    "    matrix = np.zeros(len(word_idx_map) + 1) # 最後一個是標記\n",
    "    for token in tokens:\n",
    "        idx = word_idx_map[token]\n",
    "        matrix[idx] += 1\n",
    "    matrix = matrix / matrix.sum() # 正規化數據提升未來準確度\n",
    "    matrix[-1] = label\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(pos_tokenized) + len(neg_tokenized)   # (N x D+1) 矩陣 (擺在一塊將來便於 shuffle)\n",
    "\n",
    "data = np.zeros((N, len(word_idx_map) + 1))\n",
    "\n",
    "idx = 0\n",
    "\n",
    "for tokens in pos_tokenized:\n",
    "    data[idx] = tokens_to_vector(tokens, 1)\n",
    "    idx += 1\n",
    "\n",
    "for tokens in neg_tokenized:\n",
    "    data[idx] = tokens_to_vector(tokens, 0)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
