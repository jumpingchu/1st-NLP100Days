{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 了解如何使用CkipTagger進行斷詞\n",
    "\n",
    "CkipTagger為台灣中央研究院詞庫小組所開發的NLP(自然語言處理)套件，是個以深度學習模型為基礎而成的NLP(自然語言處理)應用。 其訓練的文本資料來源為中央社、wiki (用舊版套件先進行斷詞) 及 ASBC(Academia Sinica Balanced Corpus)(為期近10年人工標記)。\n",
    "\n",
    "## 其主要模型功能有:\n",
    "\n",
    "* `WS: 斷詞`\n",
    "* `POS: 詞性標注`\n",
    "* `NER: 實體辨識`\n",
    "\n",
    "## 下載預訓練模型權重\n",
    "我們可以由CkipTagger官方Github上提供的連結路近來下載所需的預訓練模型:\n",
    "\n",
    "* `iis-ckip`\n",
    "* `gdrive-ckip`\n",
    "* `gdrive-jacobvsdanniel`\n",
    "\n",
    "也可以使用CkipTagger中所提供的API來進行模型的下載，在這個範例中我們使用其提供的API來進行模型下載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1efHsY16pxK0lBD2gYCgCTnv1Swstq771\n",
      "To: /Users/jiaping/Desktop/Coding/1st-NLP100Days/homework/Day007/data.zip\n",
      "1.88GB [03:25, 9.12MB/s]\n"
     ]
    }
   ],
   "source": [
    "data_utils.download_data_gdown('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "#from ckiptagger import data_utils\n",
    "\n",
    "#設定儲存路徑(存在與此ipynb相同的目錄下)\n",
    "#注意: 此模型需2GB的儲存空間\n",
    "#path_to_store = './'\n",
    "\n",
    "\n",
    "#我們可以使用提供的API從iis-ckip或gdrive-ckip進行下載\n",
    "#這裡我們使用gdrive-ckip進行下載\n",
    "\n",
    "#從iis-ckip下載\n",
    "#data_utils.download_data_url(\"./\")\n",
    "\n",
    "\n",
    "#下載到path_to_store並解壓縮(預設下載的壓縮檔為data.zip)\n",
    "#data_utils.download_data_gdown(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 觀察character embedding與word embedding的list\n",
    "\n",
    "因為CkipTagger是結合了word-level與character-level的方法同時對word跟character進行分析，因此我們可以看到從下載的權重資料夾中(data)包含了embedding_character與embedding_word。 現在我們來觀察一下其所使用的字典資料。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "單字總數：13136\n",
      "向量總數：13136\n"
     ]
    }
   ],
   "source": [
    "char_token_list = np.load('data/embedding_character/token_list.npy')\n",
    "char_vec_list = np.load('data/embedding_character/vector_list.npy')\n",
    "print(f'單字總數：{len(char_token_list)}\\n向量總數：{len(char_vec_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每個單字有 (300,) 維向量\n",
      "第一個單字: ,\n",
      "第一個單字向量: [ 9.06846821e-02 -3.91008481e-02 -4.38107513e-02 -2.78249998e-02\n",
      " -6.59082830e-03  9.82730538e-02 -3.30615602e-02 -3.32455598e-02\n",
      " -8.25216696e-02 -5.97619563e-02 -2.15497568e-01  1.21742591e-01\n",
      "  8.44441280e-02  6.46698922e-02 -1.73088256e-02  5.60178608e-02\n",
      " -4.69524190e-02  3.83560695e-02  2.81602979e-01 -1.05296642e-01\n",
      "  2.53045380e-01 -1.28228694e-01  4.38064672e-02  8.75911787e-02\n",
      "  6.25642985e-02 -4.81812134e-02  4.59593609e-02  7.77227730e-02\n",
      "  1.72905862e-01 -1.51137233e-01 -3.13500345e-01  1.51329324e-01\n",
      "  3.79214510e-02 -3.17767225e-02 -6.73223007e-03 -1.10702842e-01\n",
      "  1.52048752e-01  2.12142825e-01 -9.31895450e-02  1.12124726e-01\n",
      "  1.25201389e-01  5.70141450e-02 -1.24505214e-01 -4.11491245e-02\n",
      " -7.26862326e-02 -1.22127883e-01 -1.16852924e-01  8.49076360e-02\n",
      " -2.08125204e-01  8.73672292e-02  4.89221141e-02  4.23294865e-02\n",
      " -1.74451604e-01 -7.16942502e-03 -1.21610258e-02 -3.41356136e-02\n",
      " -3.82989980e-02  1.12134412e-01  8.02825466e-02  9.11359210e-03\n",
      "  1.13478094e-01  1.29445091e-01  6.40380606e-02  1.76900625e-02\n",
      "  4.61053923e-02  7.33755082e-02  1.08992504e-02  7.83749670e-02\n",
      " -1.41926277e-02 -8.53404403e-02 -9.78012756e-02 -1.44065350e-01\n",
      "  8.62638876e-02  6.97278837e-03 -6.40685707e-02  3.79135944e-02\n",
      "  4.65902872e-02 -1.72428340e-01  2.67661531e-02  1.24722809e-01\n",
      " -1.38472855e-01  4.42907512e-02  1.74038038e-01 -1.34959385e-01\n",
      "  1.46677988e-02 -3.02094761e-02 -1.37570962e-01 -1.41995132e-01\n",
      " -6.18368126e-02  7.30602369e-02  1.05070055e-01 -7.68292397e-02\n",
      " -1.50753587e-01 -6.10448271e-02 -1.59212843e-01 -1.30964845e-01\n",
      "  3.86243984e-02  7.33664110e-02  2.66788304e-02  1.98811695e-01\n",
      "  4.52414081e-02  4.46835198e-02 -7.95896500e-02 -3.03530460e-03\n",
      " -1.55150175e-01  6.27192482e-02  8.75679031e-02  5.65219000e-02\n",
      " -1.73163414e-02 -6.20095432e-02  8.07185322e-02  1.67459875e-01\n",
      "  7.90930528e-04 -1.11758702e-01  8.94727260e-02  4.75950390e-02\n",
      " -6.63264319e-02 -1.40002221e-02  1.31497771e-01 -3.08068134e-02\n",
      " -1.45550177e-01  9.82181262e-03 -1.29482478e-01 -8.09271261e-02\n",
      "  1.66991539e-02  4.39598188e-02  2.00056117e-02  1.01969335e-02\n",
      "  6.17901422e-02  1.14607230e-01  4.69653197e-02  2.60093007e-02\n",
      "  6.68954477e-03 -1.74519941e-01  9.83950421e-02  7.46878833e-02\n",
      " -3.46854213e-03 -1.59405768e-01  3.59133407e-02  6.91072568e-02\n",
      " -9.52909589e-02 -4.96073347e-03 -1.16257966e-02  6.51877150e-02\n",
      " -8.87995213e-02 -1.54385507e-01  1.04836963e-01 -8.61508399e-02\n",
      "  2.40677968e-01 -1.13241166e-01  9.13981125e-02 -7.10511655e-02\n",
      " -2.06858635e-01  1.93280280e-01 -1.91787958e-01  6.67862222e-02\n",
      "  2.75459364e-02 -4.11829911e-02  5.99045269e-02  2.85991412e-02\n",
      "  1.46133050e-01 -5.61964251e-02 -8.27574059e-02  5.35058007e-02\n",
      " -3.16127613e-02  2.61195272e-01  3.56103890e-02 -3.84976082e-02\n",
      " -1.25510424e-01  2.60743320e-01 -1.71189141e-02  1.12648904e-01\n",
      "  1.22326482e-02  1.90730917e-03  1.44645154e-01  1.79121137e-01\n",
      "  1.53291337e-02 -1.16392590e-01  5.46964770e-03 -8.08295794e-03\n",
      "  7.76347071e-02 -7.39768222e-02 -3.97990644e-02 -1.25500560e-01\n",
      " -2.39992216e-02  5.64531423e-02  1.09992459e-01 -2.16938034e-01\n",
      " -1.26922429e-01 -1.08419135e-01  3.73323858e-02 -4.98144962e-02\n",
      " -2.19714776e-01  1.22603230e-01  1.07227020e-01  2.65254676e-02\n",
      "  4.02163640e-02 -2.17892095e-01  2.06510291e-01  1.04457915e-01\n",
      " -4.83525433e-02 -6.58503622e-02 -7.78224021e-02 -8.42595696e-02\n",
      "  4.88764793e-02 -3.79936397e-02 -2.77466774e-02 -1.63822755e-01\n",
      " -1.42525867e-01 -5.32636978e-02  1.82422940e-02  1.41737731e-02\n",
      "  4.29370627e-02 -3.13092992e-02  3.52964317e-03  1.22559153e-01\n",
      " -1.11738160e-01  1.39347211e-01 -3.13593559e-02 -1.22478835e-01\n",
      "  7.62271229e-03  1.74220987e-02  3.70498560e-02  8.56986716e-02\n",
      "  9.29932818e-02  3.72319035e-02 -1.13527663e-01  4.72747870e-02\n",
      " -2.33868361e-02 -4.43437286e-02  1.20790593e-01 -8.32006931e-02\n",
      " -1.69902682e-01 -1.05089262e-01  7.90346786e-02 -2.70119533e-02\n",
      " -9.47252214e-02  5.20231389e-02 -3.23927775e-02 -1.19481266e-01\n",
      " -2.05410141e-02  1.28920615e-01  9.12860408e-02 -1.74129367e-01\n",
      " -1.20652795e-01  1.91603266e-02 -1.19546920e-01  9.96586829e-02\n",
      " -7.08970577e-02 -1.47783838e-03 -6.31524399e-02  7.02281222e-02\n",
      "  8.35030526e-02 -2.17610389e-01 -1.25490260e-04 -1.61672994e-01\n",
      " -1.77072734e-01  5.85131608e-02 -4.54604551e-02  7.62465224e-02\n",
      "  1.36121750e-01  1.31327763e-01 -2.27105524e-02 -1.51810929e-01\n",
      " -1.39065981e-01 -2.13375419e-01 -5.43276668e-02  1.80332195e-02\n",
      "  2.96390876e-02 -2.41522938e-02  3.79580222e-02  1.71646535e-01\n",
      " -7.51935542e-02  2.57654816e-01  6.33289292e-02 -5.32280281e-03\n",
      " -5.72098494e-02 -1.17022119e-01 -1.76434964e-02  9.82644781e-03\n",
      "  3.51703800e-02 -8.18159059e-02  5.52424528e-02 -1.07250266e-01\n",
      " -1.32433781e-02 -1.70687083e-02 -6.53553680e-02 -4.81555201e-02\n",
      " -1.53124682e-04 -6.30265102e-02  2.26628724e-02  1.00234054e-01\n",
      " -2.54234914e-02  1.27998754e-01  3.79470363e-02 -4.95933332e-02\n",
      " -7.07855672e-02 -1.25846893e-01 -2.69659132e-01 -6.63405359e-02]\n"
     ]
    }
   ],
   "source": [
    "print(f'每個單字有 {char_vec_list[0].shape} 維向量')\n",
    "print(f'第一個單字: {char_token_list[0]}')\n",
    "print(f'第一個單字向量: {char_vec_list[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_token_list = np.load('data/embedding_word/token_list.npy')\n",
    "word_vec_list = np.load('data/embedding_word/vector_list.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "詞總數：1355791\n",
      "詞向量總數：1355791\n"
     ]
    }
   ],
   "source": [
    "print(f'詞總數：{len(word_token_list)}\\n詞向量總數：{len(word_vec_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每個單字有 (300,) 維向量\n",
      "第一個詞: ,\n",
      "第一個詞向量: [-7.04593956e-02  1.47206234e-02 -2.17633303e-02  3.84915806e-02\n",
      " -8.14021658e-03 -1.49849132e-01  3.05930376e-01 -1.39948828e-02\n",
      " -1.50043756e-01 -7.75195658e-02  8.82805884e-02  3.31495851e-02\n",
      " -1.92563668e-01 -9.70893130e-02  8.34631994e-02 -2.34549537e-01\n",
      " -2.51720548e-01  1.86242282e-01  1.99081331e-01 -3.67115512e-02\n",
      "  3.39742601e-02  1.31627202e-01 -2.87195891e-01 -1.11317985e-01\n",
      "  2.74431705e-01 -2.68862844e-01 -1.16930470e-01 -5.81664294e-02\n",
      " -7.40866065e-02  2.82087058e-01  5.21337334e-03  1.59894779e-01\n",
      "  3.87538560e-02 -1.48833469e-01  7.83642530e-02 -5.95185868e-02\n",
      "  1.17833622e-01  3.89740840e-02 -2.20493034e-01  3.34199667e-01\n",
      " -7.37467557e-02  4.34990935e-02  1.52543530e-01  9.53945145e-02\n",
      " -3.00750673e-01 -6.92686364e-02  2.06759721e-01  3.42537582e-01\n",
      " -2.41280481e-01 -4.14551914e-01  1.50770664e-01 -1.13943636e-01\n",
      " -1.09684713e-01 -2.53322840e-01 -5.62233515e-02  3.54344040e-01\n",
      "  3.70649211e-02  8.97323266e-02  1.80452034e-01 -1.63081899e-01\n",
      " -5.88238388e-02 -1.34663090e-01  1.41335502e-01  1.51783720e-01\n",
      " -4.67665456e-02 -6.71542361e-02  4.43777628e-02  1.43644542e-01\n",
      "  1.07903788e-02  9.20652673e-02 -3.01797092e-01 -1.33671746e-01\n",
      "  7.38810599e-02 -7.32197389e-02  4.92386781e-02  3.11217159e-01\n",
      "  8.00576210e-02 -2.90661901e-01  1.37733787e-01 -1.56678036e-01\n",
      " -1.49875715e-01  2.76921187e-02 -1.03436783e-01 -1.97693661e-01\n",
      "  1.59943312e-01 -4.09238748e-02 -1.89678103e-01  9.64031890e-02\n",
      "  1.73042253e-01 -1.70557931e-01 -3.41971703e-02 -6.71339929e-02\n",
      "  2.48926476e-01 -2.20966250e-01  1.50545686e-01 -3.94051462e-01\n",
      "  1.27789739e-03 -2.35663369e-01  3.05138137e-02  9.40076485e-02\n",
      " -2.38409918e-02  1.44430893e-02 -4.58099656e-02  8.38286988e-03\n",
      " -1.12687591e-02 -3.04607172e-02  1.20265316e-02  1.77469373e-01\n",
      "  2.16166869e-01 -5.45786135e-02  2.47364491e-02 -2.51854360e-02\n",
      "  6.81429775e-03 -1.03427716e-01  2.84087121e-01  7.11692870e-02\n",
      "  2.46420816e-01  8.41843635e-02  3.13875198e-01 -9.11672711e-02\n",
      "  1.94168389e-01 -2.41055153e-02  1.53915375e-01 -2.50603035e-02\n",
      " -3.48728925e-01  2.02366740e-01  1.12415813e-01 -6.64126799e-02\n",
      "  3.71902406e-01  8.57562348e-02 -5.08277677e-02 -9.69476774e-02\n",
      " -9.68732231e-04 -2.03105003e-01  1.91507891e-01 -1.79092914e-01\n",
      "  1.17403544e-01  2.00964510e-01  1.27277493e-01  8.76787677e-02\n",
      "  1.54584095e-01  1.34593144e-01  1.66091457e-01  2.15285972e-01\n",
      " -2.43366361e-01  1.50690481e-01 -9.86017287e-02 -1.91115782e-01\n",
      "  4.45092730e-02  7.69602461e-03 -3.40792648e-02 -2.00576618e-01\n",
      "  1.68580800e-01  2.16938071e-02  3.74750584e-01 -2.20219895e-01\n",
      "  3.02663352e-02 -4.74811703e-01  6.63665980e-02  1.50100455e-01\n",
      " -1.78371608e-01  1.72931969e-01 -2.61550814e-01  1.10164583e-02\n",
      " -3.95183824e-02 -9.20150243e-03  2.24698529e-01  1.99254617e-01\n",
      " -1.95256695e-01  6.70916140e-02  1.38484731e-01 -5.71559370e-02\n",
      " -2.66541094e-01 -2.79737543e-02  1.57399848e-01 -2.89282024e-01\n",
      "  1.85803056e-01 -1.13252439e-01  2.57030930e-02  1.53389752e-01\n",
      " -6.48933351e-02  5.16370274e-02  1.16978317e-01  3.31100792e-01\n",
      " -9.32912081e-02  4.77826744e-02 -1.99413281e-02 -8.77161250e-02\n",
      "  3.12503390e-02 -1.07830755e-01 -1.32634491e-01  1.00177035e-01\n",
      "  1.01093620e-01  1.50940016e-01 -1.68437228e-01 -2.00184301e-01\n",
      "  1.84440747e-01  9.15798023e-02  6.37469962e-02 -1.33901881e-02\n",
      "  7.53609017e-02  3.16562653e-02  1.28656738e-02  1.51168862e-02\n",
      "  3.12377304e-01  1.51766986e-01  2.08265141e-01  8.07593167e-02\n",
      " -6.49781479e-03  1.43811464e-01  2.12812261e-03 -1.19807564e-01\n",
      "  1.50419883e-02  1.24120288e-01 -1.49431780e-01 -1.22273766e-01\n",
      "  7.49182254e-02 -1.72638714e-01  1.70485303e-02 -9.92716551e-02\n",
      " -5.78046553e-02 -1.83787853e-01 -1.37508512e-01 -5.79508878e-02\n",
      " -6.38621226e-02  7.18659982e-02  7.57529140e-02 -1.94216043e-01\n",
      " -1.09352767e-02  2.95141968e-03 -4.59876901e-04 -4.91452739e-02\n",
      "  1.72067836e-01  1.24109671e-01 -1.28005579e-01 -6.41145036e-02\n",
      "  1.90586716e-01 -1.58924639e-01  2.53077596e-01 -8.49416107e-02\n",
      " -2.70350417e-03  2.12272137e-01 -1.18544623e-01  5.85327437e-03\n",
      " -1.84571907e-01  1.13793109e-02  2.37178937e-01 -2.50950873e-01\n",
      " -4.14049745e-01 -2.11939752e-01 -7.46454448e-02  2.06092611e-01\n",
      " -3.29141200e-01  1.33346260e-01  1.79121718e-01 -1.07763506e-01\n",
      " -9.79290605e-02  2.50356644e-01  8.59361514e-02 -3.28559607e-01\n",
      "  9.59519595e-02  1.13524184e-01  1.18555896e-01  7.26797953e-02\n",
      "  2.85679251e-01 -1.89768896e-01  2.58635104e-01  2.43775547e-02\n",
      "  1.34007141e-01  4.94911000e-02 -6.85266182e-02 -1.23786412e-01\n",
      " -2.09208325e-01  1.47563100e-01  1.30839512e-01  1.02502115e-01\n",
      "  1.84222907e-01 -4.24427658e-01  8.98060426e-02  1.01881221e-01\n",
      "  2.32087389e-01 -8.99384767e-02 -3.02721143e-01  1.93114296e-01\n",
      " -5.24053052e-02 -1.41560480e-01  2.69189268e-01 -1.46804258e-01\n",
      " -1.75404787e-01 -2.09481083e-02  9.72518474e-02  2.01847538e-01\n",
      "  2.67004162e-01 -9.38915312e-02 -7.81608105e-04 -7.76666924e-02\n",
      "  3.19585979e-01  6.70808032e-02 -1.38977617e-01 -1.12411482e-02]\n"
     ]
    }
   ],
   "source": [
    "print(f'每個單字有 {word_vec_list[0].shape} 維向量')\n",
    "print(f'第一個詞: {word_token_list[0]}')\n",
    "print(f'第一個詞向量: {word_vec_list[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 使用CkipTagger進行斷詞\n",
    "因為CkipTagger是基於TensorFlow搭建的Cross-BiLSTM深度學習模型，因此在進行斷詞、詞性標註、命名實體識別時可以使用GPU加速操作。 在此練習中我們會使用CPU的版本進行，對使用GPU有興趣的讀者，可以參照CkipTagger官方Github進行架設。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import WS, POS, NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WS 斷詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = WS('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_zhtw = [\n",
    "    '小明碩士畢業於國立臺灣大學，現在在日本東京大學進修深造',\n",
    "     \"… 你確定嗎… 不要再騙了……\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['小明', '碩士', '畢業', '於', '國立', '臺灣', '大學', '，', '現在', '在', '日本', '東京', '大學', '進修', '深造'], ['…', ' ', '你', '確定', '嗎', '…', ' ', '不要', '再', '騙', '了', '…', '…']]\n"
     ]
    }
   ],
   "source": [
    "word_list = ws(\n",
    "    input_zhtw,\n",
    ")\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['小明', '碩士', '畢業', '於', '國立', '臺灣', '大學', '，', '現在', '在', '日本', '東京', '大學', '進修', '深造'], ['…', ' ', '你', '確定', '嗎', '…', ' ', '不要', '再', '騙', '了', '…', '…']]\n"
     ]
    }
   ],
   "source": [
    "word_list = ws(\n",
    "    input_zhtw,\n",
    "    sentence_segmentation = True, # To consider delimiters\n",
    "    segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"} # This is the defualt set of delimiters\n",
    "\n",
    ")\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS 詞性標註"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = POS('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Nb', 'Na', 'VH', 'P', 'A', 'Nc', 'Nc', 'COMMACATEGORY', 'Nd', 'P', 'Nc', 'Nc', 'Nc', 'VC', 'VA'], ['ETCCATEGORY', 'WHITESPACE', 'Nh', 'VK', 'T', 'ETCCATEGORY', 'WHITESPACE', 'D', 'D', 'VC', 'Di', 'ETCCATEGORY', 'ETCCATEGORY']]\n"
     ]
    }
   ],
   "source": [
    "pos_list = pos(word_list)\n",
    "print(pos_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NER 實體辨識"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（字串起始位置, 字串結束位置, 命名實體類別, 字串）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = NER('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{(17, 23, 'ORG', '日本東京大學'), (7, 13, 'ORG', '國立臺灣大學')}, set()]\n"
     ]
    }
   ],
   "source": [
    "entity_list = ner(word_list, pos_list)\n",
    "print(entity_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 帶入自定義字典\n",
    "如同結巴一樣, CkipTagger 也提供使用者輸入自定義字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import construct_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_weight = {\n",
    "    \"土地公\": 1,\n",
    "    \"土地婆\": 1,\n",
    "    \"公有\": 2,\n",
    "    \"\": 1,\n",
    "    \"來亂的\": \"啦\",\n",
    "    \"國立臺灣大學\": 1,\n",
    "    \"日本東京\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1 = construct_dictionary(word_to_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2, {'公有': 2.0}), (3, {'土地公': 1.0, '土地婆': 1.0}), (4, {'日本東京': 1.0}), (6, {'國立臺灣大學': 1.0})]\n"
     ]
    }
   ],
   "source": [
    "print(dict1)  \n",
    "# 返回 list(字數, {'字串': 權重})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "word_to_weight = {\n",
    "    \"日本東京大學\": 1\n",
    "}\n",
    "dict2 = construct_dictionary(word_to_weight)\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['小明', '碩士', '畢業', '於', '國立臺灣大學', '，', '現在', '在', '日本東京大學', '進修', '深造'], ['…', ' ', '你', '確定', '嗎', '…', ' ', '不要', '再', '騙', '了', '…', '…']]\n"
     ]
    }
   ],
   "source": [
    "word_list = ws(\n",
    "    input_zhtw,\n",
    "    sentence_segmentation = True,\n",
    "    segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"},\n",
    "    recommend_dictionary = dict1,\n",
    "    coerce_dictionary = dict2\n",
    ")\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定義字典前：`國立臺灣大學` --> `國立`, `臺灣`, `大學`\n",
    "\n",
    "自定義字典後：`國立臺灣大學` --> `國立臺灣大學`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用字典前：`日本東京大學` --> `日本`, `東京`, `大學`\n",
    "\n",
    "使用建議字典後：`日本東京大學` --> `日本東京`, `大學`\n",
    "\n",
    "使用強制字典後：`日本東京大學` --> `日本東京大學`（優先使用強制字典）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
